name: Force Deploy VPS
on: workflow_dispatch

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to VPS
        uses: appleboy/ssh-action@v1.0.3
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          IMAGE_TAG: ${{ github.sha }}
        with:
          host: ${{ secrets.VPS_HOST }}
          username: root
          key: ${{ secrets.VPS_SSH_KEY }}
          timeout: 60m
          command_timeout: 60m
          envs: GITHUB_TOKEN,IMAGE_TAG
          script: |
            # ============================================
            # REPO SYNC
            # ============================================
            # Ensure the directory exists
            if [ ! -d "/opt/rejourney" ]; then
              echo "Directory /opt/rejourney not found, cloning..."
              git clone https://${GITHUB_TOKEN}@github.com/${{ github.repository }}.git /opt/rejourney
            fi

            # SAFE CD: Exit if cd fails
            cd /opt/rejourney || exit 1

            # Use token for origin to allow fetching
            git remote set-url origin https://${GITHUB_TOKEN}@github.com/${{ github.repository }}.git

            # If it's not a git repo, initialize it (fallback)
            if [ ! -d ".git" ]; then
              echo "Not a git repository, fixing..."
              # CAREFUL: Only delete if we are CONFIRMED in /opt/rejourney
              if [ "$(pwd)" == "/opt/rejourney" ]; then
                  rm -rf * .[^.]*
                  git clone https://${GITHUB_TOKEN}@github.com/${{ github.repository }}.git .
              else
                  echo "CRITICAL ERROR: Wrong directory $(pwd). Aborting wipe."
                  exit 1
              fi
            else
              git fetch origin main
              git reset --hard origin/main
            fi

            # ============================================
            # UPDATE MANIFESTS
            # ============================================
            # Update manifests with correct images (scoped to this repository)
            sed -i "s|image: ghcr.io/${{ github.repository }}/api:.*|image: ghcr.io/${{ github.repository }}/api:${IMAGE_TAG}|g" k8s/*.yaml
            sed -i "s|image: ghcr.io/${{ github.repository }}/web:.*|image: ghcr.io/${{ github.repository }}/web:${IMAGE_TAG}|g" k8s/*.yaml
            sed -i "s|image: ghcr.io/${{ github.repository }}/migration:.*|image: ghcr.io/${{ github.repository }}/migration:${IMAGE_TAG}|g" k8s/*.yaml

            # ============================================
            # CLEANUP OLD JOBS
            # ============================================
            # Delete old migration/setup jobs and WAIT for them to be fully removed
            echo "ðŸ—‘ï¸ Deleting old migration jobs..."
            kubectl delete job db-migrate db-seed db-setup -n rejourney --ignore-not-found --wait=true --timeout=60s

            # Also delete any leftover pods from previous job runs
            kubectl delete pods -n rejourney -l job-name=db-setup --ignore-not-found --wait=true --timeout=30s || true
            kubectl delete pods -n rejourney -l job-name=db-migrate --ignore-not-found --wait=true --timeout=30s || true
            kubectl delete pods -n rejourney -l job-name=db-seed --ignore-not-found --wait=true --timeout=30s || true

            echo "âœ… Old migration jobs cleaned up"

            # ============================================
            # APPLY MANIFESTS
            # ============================================
            # First apply namespace (not pruned)
            kubectl apply -f k8s/namespace.yaml

            # Configure Traefik to trust Cloudflare headers for real client IP forwarding
            # This goes to kube-system namespace, separate from the pruned apply
            kubectl apply -f k8s/traefik-config.yaml

            # Auto-install cert-manager if missing (Required for SSL)
            if ! kubectl get namespace cert-manager &> /dev/null; then
              echo "ðŸ”’ cert-manager not found. Installing..."
              kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.16.2/cert-manager.yaml

              echo "â³ Waiting for cert-manager to be ready..."
              kubectl wait --for=condition=Available deployment/cert-manager-webhook -n cert-manager --timeout=300s
            fi

            # Apply all other manifests with prune enabled
            # This automatically deletes resources that are no longer in the YAML files
            # NOTE: PersistentVolumeClaims are NOT in prune-allowlist = Postgres data is SAFE
            kubectl apply -f k8s/ \
              --prune \
              -l app.kubernetes.io/part-of=rejourney \
              --prune-allowlist=core/v1/ConfigMap \
              --prune-allowlist=core/v1/Service \
              --prune-allowlist=apps/v1/Deployment \
              --prune-allowlist=apps/v1/StatefulSet \
              --prune-allowlist=networking.k8s.io/v1/Ingress \
              --prune-allowlist=traefik.io/v1alpha1/Middleware \
              --prune-allowlist=batch/v1/CronJob \
              --prune-allowlist=batch/v1/Job

            # Clean up stale cert-manager resources
            kubectl delete challenges --all -A --wait=false
            kubectl delete orders --all -A --wait=false

            # ============================================
            # WAIT FOR DEPENDENCIES
            # ============================================
            # Wait for postgres to be ready before migration runs
            echo "â³ Waiting for PostgreSQL to be ready..."
            kubectl wait --for=condition=ready pod -l app=postgres -n rejourney --timeout=120s || {
              echo "âš ï¸ PostgreSQL not ready, checking status..."
              kubectl describe pod -l app=postgres -n rejourney
            }

            # Wait for migration job to complete before restarting services
            echo "â³ Waiting for db-setup migration job to complete..."
            kubectl wait --for=condition=complete job/db-setup -n rejourney --timeout=360s || {
              echo "âš ï¸ Migration job did not complete in time. Checking status..."
              kubectl describe job db-setup -n rejourney
              kubectl logs job/db-setup -n rejourney -c wait-postgres --tail=20 || true
              kubectl logs job/db-setup -n rejourney -c setup --tail=50 || true
              echo "âŒ Migration may have failed - proceeding with deployment but check logs!"
            }

            # ============================================
            # RESTART DEPLOYMENTS
            # ============================================
            # Restart deployments to force pulling latest images
            kubectl rollout restart deployment api -n rejourney
            kubectl rollout restart deployment web -n rejourney
            kubectl rollout restart deployment ingest-worker -n rejourney
            kubectl rollout restart deployment retention-worker -n rejourney
            kubectl rollout restart deployment alert-worker -n rejourney || echo "Alert worker might be in progress..."

            # ============================================
            # CLEANUP
            # ============================================
            echo "ðŸ§¹ Running post-deploy cleanup..."

            # 1. Clean up old images to prevent bloat
            echo "  â†’ Cleaning old container images..."
            if command -v crictl &> /dev/null; then
              crictl rmi --prune
            elif command -v docker &> /dev/null; then
              docker image prune -af --filter "until=24h"
            else
              echo "âš ï¸ Neither docker nor crictl found. Skipping image cleanup."
            fi

            # 2. Clean up completed/failed pods
            echo "  â†’ Cleaning completed pods..."
            kubectl delete pods -n rejourney --field-selector=status.phase==Succeeded --ignore-not-found
            kubectl delete pods -n rejourney --field-selector=status.phase==Failed --ignore-not-found

            # 3. Clean up old debug pods
            echo "  â†’ Cleaning stale debug pods..."
            kubectl get pods -n rejourney --no-headers -o custom-columns=":metadata.name" | grep "^debug-" | xargs -r kubectl delete pod -n rejourney --ignore-not-found || true

            # 4. Clean up old completed jobs (keep last 3)
            echo "  â†’ Cleaning old job pods..."
            kubectl get pods -n rejourney -o name | grep -E 'postgres-backup-|db-setup|db-migrate|db-seed' | head -n -3 | xargs -r kubectl delete -n rejourney --ignore-not-found || true

            # 5. Clean containerd garbage (exited containers)
            echo "  â†’ Cleaning exited containers..."
            if command -v crictl &> /dev/null; then
              crictl rm $(crictl ps -a -q --state exited) 2>/dev/null || true
            fi

            echo "âœ… Deployment complete!"
